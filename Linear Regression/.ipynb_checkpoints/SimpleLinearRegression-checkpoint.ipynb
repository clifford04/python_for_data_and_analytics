{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression \n",
    "\n",
    "Linear regression assumes a linear or straight line relationship between the input variables (X) and the single output variable (y). More specically, a linear regression model allows us to calculate (i.e. predict or estimate) the output (y) from a\n",
    "linear combination of the input variables (X). When there is a single input variable, the method\n",
    "is referred to as a simple linear regression.\n",
    "\n",
    "\n",
    "Simple linear regression produces a model in the form:\n",
    "\n",
    "ŷ = α + Bx\n",
    "\n",
    "* ŷ - response variable (a.k.a the output variable a.k.a the value we are trying to predict)\n",
    "* α - intercept\n",
    "* B - regression coefficient\n",
    "* x - predictor variable (a.k.a input variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3/21/2018</td>\n",
       "      <td>171.27</td>\n",
       "      <td>36387880</td>\n",
       "      <td>175.04</td>\n",
       "      <td>175.09</td>\n",
       "      <td>171.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3/20/2018</td>\n",
       "      <td>175.24</td>\n",
       "      <td>19620520</td>\n",
       "      <td>175.24</td>\n",
       "      <td>176.80</td>\n",
       "      <td>174.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3/19/2018</td>\n",
       "      <td>175.30</td>\n",
       "      <td>32931110</td>\n",
       "      <td>177.32</td>\n",
       "      <td>177.47</td>\n",
       "      <td>173.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3/16/2018</td>\n",
       "      <td>178.02</td>\n",
       "      <td>38313330</td>\n",
       "      <td>178.65</td>\n",
       "      <td>179.12</td>\n",
       "      <td>177.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3/15/2018</td>\n",
       "      <td>178.65</td>\n",
       "      <td>22676520</td>\n",
       "      <td>178.50</td>\n",
       "      <td>180.24</td>\n",
       "      <td>178.0701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   close    volume    open    high       low\n",
       "0  3/21/2018  171.27  36387880  175.04  175.09  171.2600\n",
       "1  3/20/2018  175.24  19620520  175.24  176.80  174.9400\n",
       "2  3/19/2018  175.30  32931110  177.32  177.47  173.6600\n",
       "3  3/16/2018  178.02  38313330  178.65  179.12  177.6200\n",
       "4  3/15/2018  178.65  22676520  178.50  180.24  178.0701"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this exercise we will use a dataset of Nasdaq Apple Inc. Common Stock Historical Stock Prices\n",
    "# https://www.nasdaq.com/symbol/aapl/historical\n",
    "df = pd.read_csv(\"apple_stocks.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1169049d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the data and see if there are any interesting patterns \n",
    "# that we can observe in the relationship between 'high' and 'close'\n",
    "df.plot.scatter(x='high', y='close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression With \"Pen and Paper\"\n",
    "\n",
    "As mentioned above, we need to derive the following formula from the data:\n",
    "\n",
    "ŷ = α + Bx\n",
    "\n",
    "In order to derive this formula, we need to take the following steps:\n",
    "\n",
    "1. Calculate the mean of the X variable.\n",
    "2. Calculate the difference between each X and the mean X.\n",
    "3. Square the differences and add it all up and divide by the number of values in your data column / list.  This is SSxx (variance of x).\n",
    "4. Calculate the mean of the Y variable.\n",
    "5. Calculate the variance of the Y variable.\n",
    "6. Multiply the differences (of X and Y from their respective means), add them all together  This is SSxy (covariance of y and x).\n",
    "7. Using SSxx and SSxy, you calculate the intercept by subtracting SSxx / SSxy * AVG(X) from AVG(Y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Data**\n",
    "Let's take a small subset of our stocks data, something that we can easily do calculations on by hand\n",
    "\n",
    "|The highest price of the stock during a given day (x)|The price of the stock at closing (y)|\n",
    "| ----------- | ----------- |\n",
    "|175.09|171.27|\n",
    "|176.80|175.24|\n",
    "|177.47|175.30|\n",
    "|179.12|178.02|\n",
    "|180.24|178.65|\n",
    "\n",
    "\n",
    "**Step 1: Calculate the mean of our X variable.**\n",
    "mean(X) = (175.09 + 176.80 + 177.47 + 179.12 + 180.24) / 5 = 177.744\n",
    "\n",
    "**Step 2: Calculate the difference between each X and the mean X and each Y and the mean Y.\n",
    "\n",
    "|x| mean(x) - x |Difference between <br /> each X and the mean X|mean(y) - y | difference between <br /> each Y and the mean Y |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "|175.09|(177.744 - 175.09)|2.654| (175.696 - 171.27) | 4.426 |\n",
    "|176.80|(177.744 - 176.80)|0.943| (175.696 - 175.24) | 0.456 |\n",
    "|177.47|(177.744 - 177.47)|0.274| (175.696 - 175.30) | 0.396 |\n",
    "|179.12|(177.744 - 179.12)|-1.376| (175.696 - 178.02) | -2.324 |\n",
    "|180.24|(177.744 - 180.24)|-2.496| (175.696 - 178.65) | -2.954 |\n",
    "\n",
    "**Step 3: Calculate the variance of X (SSxx)**\n",
    "\n",
    "SSxx = (2.654)<sup>2</sup> + (0.943)<sup>2</sup> + (0.274)<sup>2</sup> + (-1.376)<sup>2</sup> + (-2.496)<sup>2</sup> = 16.133\n",
    "\n",
    "**Step 4: Calculate mean of the Y variable.**\n",
    "\n",
    "mean(Y) = (171.27 + 175.24 + 175.30 + 178.02 + 178.65) / 5 = 175.696\n",
    "\n",
    "**Step 5: Calculate the variance of the Y variable (SSyy)**\n",
    "\n",
    "SSyy = (4.426)<sup>2</sup> + (0.456)<sup>2</sup> + (0.396)<sup>2</sup> + (-2.324)<sup>2</sup> + (-2.954)<sup>2</sup> = 34.08\n",
    "\n",
    "**Step 6: Calculate the covariance of X and Y (SSxy)**\n",
    "\n",
    "SSxy = (mean(X)-X) * (mean(Y)-Y) = (2.654 * 4.426) + (0.944 * 0.456) + (0.274 * 0.396) + (-1.376 * -2.324) + (-2.496 * -2.954) = 22.857\n",
    "\n",
    "**Step 7: Calculate the slope of the line**\n",
    "\n",
    "a = SSxy / SSxx = 22.857 / 16.133 = 1.419\n",
    "\n",
    "**Step 8: Calculate the intercept**\n",
    "\n",
    "b = mean(Y) – slope * mean(X) = 175.696 - (1.419 * 177.744) = -76.52\n",
    "\n",
    "\n",
    "**Our model**\n",
    "\n",
    "ŷ = -76.52 + 1.419x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Python 'By Hand'\n",
    "### In other words, we will come up with a linear regression function without the use of any machine learning libraries - we will write our own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Calculate Mean\n",
    "The first step is to estimate the mean of both the input and output variables from the training data.  By the way, Python has functions that will do this for you, but it is helpful to actually understand how they work.\n",
    "\n",
    "The mean of a list of numbers can be calculated as:\n",
    "\n",
    "**mean = (sum of all list elements) / (number of list elements)**\n",
    "\n",
    "or, if we want to be more mathematical, we can express the formula for the mean as:\n",
    "\n",
    "<img src='../images/formulas/mean_of_list.jpg' width='30%' />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value of a list of numbers\n",
    "def mean(values):\n",
    "    return sum(values) / float(len(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:  Calculate Variance\n",
    "The second step is to estimate the variance of both the input and output variables from the training data.\n",
    "\n",
    "The sample variance is the mean of sum squared differences for each value from the mean value. \n",
    "\n",
    "Variance of a list of numbers can be calculated using the following formula:\n",
    "\n",
    "<img src='../images/formulas/variance_of_a_list.jpg' width='50%' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of a list of numbers\n",
    "def variance(values, mean):\n",
    "    s = 0.0 # sum of squared differences between xi and mean (xi - mean)^2\n",
    "    for val in x:\n",
    "        s += (val - mean_x) ** 2\n",
    "    sample_variance = s / (len(x) - 1)\n",
    "    return sample_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x stats: mean=174.155 variance=32.036\n",
      "y stats: mean=172.558 variance=32.036\n"
     ]
    }
   ],
   "source": [
    "# Let's test our mean and variance functions\n",
    "\n",
    "x = list(df['high'])\n",
    "y = list(df['close'])\n",
    "       \n",
    "mean_x, mean_y = mean(x), mean(y)\n",
    "var_x, var_y = variance(x, mean_x), variance(y, mean_y)\n",
    "\n",
    "print('x stats: mean=%.3f variance=%.3f' % (mean_x, var_x))\n",
    "print('y stats: mean=%.3f variance=%.3f' % (mean_y, var_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.15466065573773\n",
      "31.510951472550406\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(x))\n",
    "print(np.var(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Covariance\n",
    "\n",
    "<img src='../images/formulas/covariance_of_a_list.jpg' width='60%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance between x and y\n",
    "def covariance(x, mean_x, y, mean_y):\n",
    "    s = 0.0\n",
    "    for i in range(len(x)):\n",
    "        s += (x[i] - mean_x) * (y[i] - mean_y)\n",
    "        covar = s / (len(x) - 1)\n",
    "    return covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance: 19.795\n"
     ]
    }
   ],
   "source": [
    "# Let's test covariance calculations\n",
    "covar = covariance(x, mean_x, y, mean_y)\n",
    "print('Covariance: %.3f' % (covar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate coefficients\n",
    "\n",
    "<img src='../images/formulas/regression_slope.jpg' width='50%' />\n",
    "\n",
    "<img src='../images/formulas/regression_intercept.jpg' width='60%' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficients(x, y):\n",
    "    x_mean, y_mean = mean(x), mean(y)\n",
    "    # Calculate coefficient (slope)\n",
    "    b = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n",
    "    \n",
    "    # Calculate intercept\n",
    "    a = y_mean - b * x_mean\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: a=-11.032, b=1.054\n"
     ]
    }
   ],
   "source": [
    "# Let's test coefficients calculations\n",
    "a, b = coefficients(x, y)\n",
    "print('Coefficients: a=%.3f, b=%.3f' % (a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split our data into training and testing subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(x, y, test_sample_size = 0.2):\n",
    "    # Initialize resulting lists\n",
    "    x_train, y_train, x_test, y_test = [], [], [], []\n",
    "    \n",
    "    # Create a list of indexes from the original list of values\n",
    "    idx = list(range(0, len(x)))\n",
    "    \n",
    "    # Calculate how many values from the list actully constitute the \n",
    "    # test_sample_size\n",
    "    \n",
    "    num_of_values_in_test = math.floor(len(idx) * test_sample_size)\n",
    "    \n",
    "    # Randomly select a percentage of values for train / test\n",
    "    test_idx = random.sample(idx, num_of_values_in_test)\n",
    "    \n",
    "    for i in idx:\n",
    "        if i in test_idx:\n",
    "            x_test.append(x[i])\n",
    "            y_test.append(y[i])\n",
    "        else:\n",
    "            x_train.append(x[i])\n",
    "            y_train.append(y[i])\n",
    "            \n",
    "    return x_train, y_train, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = test_train_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Make predictions / estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_simple_linear_regression(a_coeff, b_coeff, x_test):\n",
    "    predictions = list()\n",
    "    \n",
    "    # Test our model by generating predictions\n",
    "    for val in x_test:\n",
    "        #print(row)\n",
    "        yhat = a + b * val\n",
    "        predictions.append(yhat)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model - calculate coefficients based\n",
    "# on the training dataset\n",
    "a, b = coefficients(x_train, y_train)\n",
    "\n",
    "pred = predict_with_simple_linear_regression(a, b, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate the model with RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate root mean squared error\n",
    "def rmse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "        mean_error = sum_error / float(len(actual))\n",
    "    return math.sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5652712249812888\n"
     ]
    }
   ],
   "source": [
    "rmse = rmse_metric(y_test, pred)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression with scikit-learn\n",
    "\n",
    "The linear regression algorithm accomplishes this by deriving a line formula that minimizes the differences between actual values and predicted values.  This algorithm is called **ordinary least-squares**, or **OLS**.\n",
    "\n",
    "**Scikit-learn** Python module provides a LinearRegression function for doing this job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this example, we will try to estimate the value of Apple stock at stock market closing\n",
    "# using the value of it's highest cost during a given day.  In other words, we will try \n",
    "# to predict the value of 'close' using the value of 'high'\n",
    "# To put this in machine learning / data mining terms, 'close' is our response variable and \n",
    "# 'high' our predictor variable\n",
    "X = df[['high']]\n",
    "y = df[['close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split Data\n",
    "# Now we can split our data into a training and test set.  In this example, we are using an 80/20 split, \n",
    "# where 80% of our data will be used for training our model, and 20% of our data will be used for testing.\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "# Now we train our LinearRegression model using the training subset of data.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for high is 1.0746199659116502\n"
     ]
    }
   ],
   "source": [
    "# Now that our model is trained, we can view the coefficients of the model using regression_model.coef_, \n",
    "# which is an array of tuples of coefficients.\n",
    "# Each regression coefficient shows the strength of the relationship between the predictor variable and the\n",
    "# outcome variable while controlling for the other predictor variable \n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept for our model is -14.705323911958175\n"
     ]
    }
   ],
   "source": [
    "# regression_model.intercept_ returns an array of intercepts\n",
    "intercept = regression_model.intercept_[0]\n",
    "\n",
    "print(\"The intercept for our model is {}\".format(intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the regression coefficient for our predictor variable and the intercept, we can figure out our model:\n",
    "\n",
    "ŷ = -14.71 - 1.074x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.78707541]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.predict(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is our model - the $R^{2}$ statistic\n",
    "\n",
    "A common method of measuring the accuracy of regression models is to use the $R^{2}$ statistic.\n",
    "\n",
    "The $R^{2}$ statistic is defined as follows:\n",
    "\n",
    "$R^{2}$ =  1 – (RSS/TSS)\n",
    "\n",
    "* The RSS (Residual sum of squares) measures the variability left unexplained after performing the regression\n",
    "* The TSS measues the total variance in Y\n",
    "* Therefore the $R^{2}$ statistic measures proportion of variability in Y that is explained by X using our model\n",
    "\n",
    "The scale of $R^{2}$ statistic ranges from zero to one, with zero indicating that the proposed model **does not improve prediction over the mean model and one indicating perfect prediction**. Improvement in the regression model results in proportional increases in R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9336198098507397"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R^2  can be determined using our test set and the model’s score method.\n",
    "\n",
    "regression_model.score(X_test, y_test)\n",
    "\n",
    "# This means that in our model, 93.3% of the variability in Y can be explained using X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
